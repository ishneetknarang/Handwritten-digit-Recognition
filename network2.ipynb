{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  #upload data
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    f = gzip.open(r'C:\\Users\\Kul Garima\\.jupyter\\DeepLearningPython35-master\\mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "\n",
    "def load_data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = list(zip(training_inputs, training_results))\n",
    "    \n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = list(zip(validation_inputs, va_d[1]))\n",
    "    \n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = list(zip(test_inputs, te_d[1]))\n",
    "    \n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticCost(object):\n",
    "\n",
    "    def fn(a, y):\n",
    "        return 0.5*np.linalg.norm(a-y)**2\n",
    "\n",
    "    def delta(z, a, y):\n",
    "        return (a-y) * sigmoid_prime(z)\n",
    "\n",
    "\n",
    "class CrossEntropyCost(object):\n",
    "    \n",
    "    def fn(a, y):        \n",
    "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "\n",
    "    def delta(z, a, y):\n",
    "        return (a-y)\n",
    "\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes, cost=CrossEntropyCost):\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.default_weight_initializer()\n",
    "        self.cost=cost\n",
    "\n",
    "    def default_weight_initializer(self):\n",
    "        \n",
    "\n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)/np.sqrt(x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def large_weight_initializer(self):\n",
    "        \n",
    "        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            lmbda = 0.0,\n",
    "            evaluation_data=None,\n",
    "            monitor_evaluation_cost=False,\n",
    "            monitor_evaluation_accuracy=False,\n",
    "            monitor_training_cost=False,\n",
    "            monitor_training_accuracy=False):\n",
    "        \n",
    "        if evaluation_data: n_data = len(evaluation_data)\n",
    "        n = len(training_data)\n",
    "        \n",
    "        evaluation_cost, evaluation_accuracy = [], []\n",
    "        training_cost, training_accuracy = [], []\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(\n",
    "                    mini_batch, eta, lmbda, len(training_data))\n",
    "            print (\"Epoch %s training complete\" % j)\n",
    "            if monitor_training_cost:\n",
    "                cost = self.total_cost(training_data, lmbda)\n",
    "                training_cost.append(cost)\n",
    "                print(\"Cost on training data: {}\".format(cost))\n",
    "            if monitor_training_accuracy:\n",
    "                accuracy = self.accuracy(training_data, convert=True)\n",
    "                training_accuracy.append(accuracy)\n",
    "                print( \"Accuracy on training data: {} / {}\".format(\n",
    "                    accuracy, n))\n",
    "            if monitor_evaluation_cost:\n",
    "                cost = self.total_cost(evaluation_data, lmbda, convert=True)\n",
    "                evaluation_cost.append(cost)\n",
    "                print (\"Cost on evaluation data: {}\".format(cost))\n",
    "            if monitor_evaluation_accuracy:\n",
    "                accuracy = self.accuracy(evaluation_data)\n",
    "                evaluation_accuracy.append(accuracy)\n",
    "                print (\"Accuracy on evaluation data: {} / {}\".format(\n",
    "                    self.accuracy(evaluation_data), n_data))\n",
    "            print\n",
    "        return evaluation_cost, evaluation_accuracy, \\\n",
    "            training_cost, training_accuracy\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, lmbda, n):\n",
    "       \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "            \n",
    "        self.weights = [(1-eta*(lmbda/n))*w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "      \n",
    "    \n",
    "        activation = x\n",
    "        activations = [x] \n",
    "        zs = [] \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "       \n",
    "    \n",
    "        delta = (self.cost).delta(zs[-1], activations[-1], y)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def accuracy(self, data, convert=False):\n",
    "        \n",
    "        if convert:\n",
    "            results = [(np.argmax(self.feedforward(x)), np.argmax(y)) for (x, y) in data]\n",
    "        else:\n",
    "            results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in data]\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "\n",
    "    def total_cost(self, data, lmbda, convert=False):\n",
    "       \n",
    "        cost = 0.0\n",
    "        for x, y in data:\n",
    "            a = self.feedforward(x)\n",
    "            if convert: y = vectorized_result(y)\n",
    "            cost += self.cost.fn(a, y)/len(data)\n",
    "        cost += 0.5*(lmbda/len(data))*sum(\n",
    "            np.linalg.norm(w)**2 for w in self.weights)\n",
    "        return cost\n",
    "\n",
    "    def save(self, filename):\n",
    "       \n",
    "        data = {\"sizes\": self.sizes,\n",
    "                \"weights\": [w.tolist() for w in self.weights],\n",
    "                \"biases\": [b.tolist() for b in self.biases],\n",
    "                \"cost\": str(self.cost.__name__)}\n",
    "        f = open(filename, \"w\")\n",
    "        json.dump(data, f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "   \n",
    "    f = open(filename, \"r\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    cost = getattr(sys.modules[__name__], data[\"cost\"])\n",
    "    net = Network(data[\"sizes\"], cost=cost)\n",
    "    net.weights = [np.array(w) for w in data[\"weights\"]]\n",
    "    net.biases = [np.array(b) for b in data[\"biases\"]]\n",
    "    return net\n",
    "\n",
    "\n",
    "def vectorized_result(j):\n",
    "    \n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def sigmoid(z):\n",
    "   \n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = load_data_wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Epoch 1 training complete\n",
      "Epoch 2 training complete\n",
      "Epoch 3 training complete\n",
      "Epoch 4 training complete\n",
      "Epoch 5 training complete\n",
      "Epoch 6 training complete\n",
      "Epoch 7 training complete\n",
      "Epoch 8 training complete\n",
      "Epoch 9 training complete\n",
      "Epoch 10 training complete\n",
      "Epoch 11 training complete\n",
      "Epoch 12 training complete\n",
      "Epoch 13 training complete\n",
      "Epoch 14 training complete\n",
      "Epoch 15 training complete\n",
      "Epoch 16 training complete\n",
      "Epoch 17 training complete\n",
      "Epoch 18 training complete\n",
      "Epoch 19 training complete\n",
      "Epoch 20 training complete\n",
      "Epoch 21 training complete\n",
      "Epoch 22 training complete\n",
      "Epoch 23 training complete\n",
      "Epoch 24 training complete\n",
      "Epoch 25 training complete\n",
      "Epoch 26 training complete\n",
      "Epoch 27 training complete\n",
      "Epoch 28 training complete\n",
      "Epoch 29 training complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [], [], [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data , 30, 10, 10.0,\n",
    "            lmbda = 5.0,\n",
    "            evaluation_data=None,\n",
    "            monitor_evaluation_cost=False,\n",
    "            monitor_evaluation_accuracy=False,\n",
    "            monitor_training_cost=False,\n",
    "            monitor_training_accuracy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 3.7058409771261513\n",
      "Accuracy on training data: 4859 / 50000\n",
      "Cost on evaluation data: 3.7041225214976614\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 3.670538127053678\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.69608972078041\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 4.120771925999175\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 4.1362586612425085\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 3.665311029941012\n",
      "Accuracy on training data: 5101 / 50000\n",
      "Cost on evaluation data: 3.6694862999290128\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 3.4974348815603915\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.492381188620574\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 3.462937399639172\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.4553823184598063\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 3.7587741451461274\n",
      "Accuracy on training data: 4506 / 50000\n",
      "Cost on evaluation data: 3.7638899940265285\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 3.552717883151975\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.539800206724652\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 3.611417485494288\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 3.624769710821914\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 3.8880883007135143\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 3.8969801803204236\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 3.754617505475407\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.7439224874808845\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 3.4411472056616264\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.4508174498823063\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 3.669493814054599\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.671398044910423\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 4.353102576128164\n",
      "Accuracy on training data: 4859 / 50000\n",
      "Cost on evaluation data: 4.348408884675333\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 3.982181181642808\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.9825290340463146\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 3.5113978774359498\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.5239122390590936\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 3.8808454191427426\n",
      "Accuracy on training data: 5101 / 50000\n",
      "Cost on evaluation data: 3.863750173480171\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 3.7872020795504806\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.790568524690881\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 3.5449970765183556\n",
      "Accuracy on training data: 4842 / 50000\n",
      "Cost on evaluation data: 3.551201729808517\n",
      "Accuracy on evaluation data: 1009 / 10000\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 3.549640683044132\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 3.5472149908514417\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 4.130569352571075\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 4.129725801548539\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 3.8221030846158537\n",
      "Accuracy on training data: 4842 / 50000\n",
      "Cost on evaluation data: 3.8182428943510454\n",
      "Accuracy on evaluation data: 1009 / 10000\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 3.740077182207115\n",
      "Accuracy on training data: 4951 / 50000\n",
      "Cost on evaluation data: 3.746249162854825\n",
      "Accuracy on evaluation data: 967 / 10000\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 3.902828692032671\n",
      "Accuracy on training data: 4968 / 50000\n",
      "Cost on evaluation data: 3.911560599323201\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 3.6002344272311717\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.590290376250039\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 3.5021910953821127\n",
      "Accuracy on training data: 5175 / 50000\n",
      "Cost on evaluation data: 3.497496592918906\n",
      "Accuracy on evaluation data: 1090 / 10000\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 3.600398779747757\n",
      "Accuracy on training data: 4932 / 50000\n",
      "Cost on evaluation data: 3.5935177408763868\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 3.7304266700380584\n",
      "Accuracy on training data: 5678 / 50000\n",
      "Cost on evaluation data: 3.737046054822728\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 4.197201472149173\n",
      "Accuracy on training data: 4988 / 50000\n",
      "Cost on evaluation data: 4.21778974471592\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 3.8035608512559453\n",
      "Accuracy on training data: 4842 / 50000\n",
      "Cost on evaluation data: 3.793227851126395\n",
      "Accuracy on evaluation data: 1009 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.7041225214976614,\n",
       "  3.69608972078041,\n",
       "  4.1362586612425085,\n",
       "  3.6694862999290128,\n",
       "  3.492381188620574,\n",
       "  3.4553823184598063,\n",
       "  3.7638899940265285,\n",
       "  3.539800206724652,\n",
       "  3.624769710821914,\n",
       "  3.8969801803204236,\n",
       "  3.7439224874808845,\n",
       "  3.4508174498823063,\n",
       "  3.671398044910423,\n",
       "  4.348408884675333,\n",
       "  3.9825290340463146,\n",
       "  3.5239122390590936,\n",
       "  3.863750173480171,\n",
       "  3.790568524690881,\n",
       "  3.551201729808517,\n",
       "  3.5472149908514417,\n",
       "  4.129725801548539,\n",
       "  3.8182428943510454,\n",
       "  3.746249162854825,\n",
       "  3.911560599323201,\n",
       "  3.590290376250039,\n",
       "  3.497496592918906,\n",
       "  3.5935177408763868,\n",
       "  3.737046054822728,\n",
       "  4.21778974471592,\n",
       "  3.793227851126395],\n",
       " [983,\n",
       "  961,\n",
       "  1064,\n",
       "  1030,\n",
       "  961,\n",
       "  967,\n",
       "  915,\n",
       "  1090,\n",
       "  1064,\n",
       "  1064,\n",
       "  961,\n",
       "  967,\n",
       "  991,\n",
       "  983,\n",
       "  967,\n",
       "  967,\n",
       "  1030,\n",
       "  961,\n",
       "  1009,\n",
       "  961,\n",
       "  990,\n",
       "  1009,\n",
       "  967,\n",
       "  990,\n",
       "  1090,\n",
       "  1090,\n",
       "  991,\n",
       "  1064,\n",
       "  961,\n",
       "  1009],\n",
       " [3.7058409771261513,\n",
       "  3.670538127053678,\n",
       "  4.120771925999175,\n",
       "  3.665311029941012,\n",
       "  3.4974348815603915,\n",
       "  3.462937399639172,\n",
       "  3.7587741451461274,\n",
       "  3.552717883151975,\n",
       "  3.611417485494288,\n",
       "  3.8880883007135143,\n",
       "  3.754617505475407,\n",
       "  3.4411472056616264,\n",
       "  3.669493814054599,\n",
       "  4.353102576128164,\n",
       "  3.982181181642808,\n",
       "  3.5113978774359498,\n",
       "  3.8808454191427426,\n",
       "  3.7872020795504806,\n",
       "  3.5449970765183556,\n",
       "  3.549640683044132,\n",
       "  4.130569352571075,\n",
       "  3.8221030846158537,\n",
       "  3.740077182207115,\n",
       "  3.902828692032671,\n",
       "  3.6002344272311717,\n",
       "  3.5021910953821127,\n",
       "  3.600398779747757,\n",
       "  3.7304266700380584,\n",
       "  4.197201472149173,\n",
       "  3.8035608512559453],\n",
       " [4859,\n",
       "  4988,\n",
       "  5678,\n",
       "  5101,\n",
       "  4988,\n",
       "  4951,\n",
       "  4506,\n",
       "  5175,\n",
       "  5678,\n",
       "  5678,\n",
       "  4988,\n",
       "  4951,\n",
       "  4932,\n",
       "  4859,\n",
       "  4951,\n",
       "  4951,\n",
       "  5101,\n",
       "  4988,\n",
       "  4842,\n",
       "  4988,\n",
       "  4968,\n",
       "  4842,\n",
       "  4951,\n",
       "  4968,\n",
       "  5175,\n",
       "  5175,\n",
       "  4932,\n",
       "  5678,\n",
       "  4988,\n",
       "  4842])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data , 30, 10, 10.0,\n",
    "            lmbda = 1000.0,\n",
    "            evaluation_data= validation_data,\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kul garima\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:185: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\kul garima\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n",
      "c:\\users\\kul garima\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  del sys.path[0]\n",
      "c:\\users\\kul garima\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: inf\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 1 training complete\n",
      "Cost on training data: inf\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 2 training complete\n",
      "Cost on training data: inf\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: inf\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 3 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kul garima\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:102: RuntimeWarning: overflow encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 4 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 5 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 6 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 7 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 8 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 9 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 10 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 11 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 12 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 13 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 14 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 15 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 16 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 17 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 18 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 19 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 20 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 21 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 22 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 23 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 24 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 25 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 26 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 27 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 28 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 29 training complete\n",
      "Cost on training data: nan\n",
      "Accuracy on training data: 97 / 1000\n",
      "Cost on evaluation data: nan\n",
      "Accuracy on evaluation data: 10 / 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([inf,\n",
       "  inf,\n",
       "  inf,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [inf,\n",
       "  inf,\n",
       "  inf,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan],\n",
       " [97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97,\n",
       "  97])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data[:1000] , 30, 10, 10.0,\n",
    "            lmbda = 1000.0,\n",
    "            evaluation_data= validation_data[:100],\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network([784, 30, 30, 30, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 3.1914391962703026\n",
      "Accuracy on training data: 7045 / 50000\n",
      "Cost on evaluation data: 3.220550444355957\n",
      "Accuracy on evaluation data: 1358 / 10000\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 1.9664736336015889\n",
      "Accuracy on training data: 25739 / 50000\n",
      "Cost on evaluation data: 2.0719999971131013\n",
      "Accuracy on evaluation data: 5206 / 10000\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 0.9946772191561473\n",
      "Accuracy on training data: 43322 / 50000\n",
      "Cost on evaluation data: 1.220167426194576\n",
      "Accuracy on evaluation data: 8713 / 10000\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.6540916048660534\n",
      "Accuracy on training data: 46082 / 50000\n",
      "Cost on evaluation data: 1.0079528829260798\n",
      "Accuracy on evaluation data: 9226 / 10000\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.5563059908524913\n",
      "Accuracy on training data: 46751 / 50000\n",
      "Cost on evaluation data: 0.9818013019900832\n",
      "Accuracy on evaluation data: 9341 / 10000\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.4693920682452468\n",
      "Accuracy on training data: 47482 / 50000\n",
      "Cost on evaluation data: 0.9389622529238528\n",
      "Accuracy on evaluation data: 9444 / 10000\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.4336847868181387\n",
      "Accuracy on training data: 47699 / 50000\n",
      "Cost on evaluation data: 0.945316914386068\n",
      "Accuracy on evaluation data: 9477 / 10000\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.3797755119085292\n",
      "Accuracy on training data: 48127 / 50000\n",
      "Cost on evaluation data: 0.905283338574934\n",
      "Accuracy on evaluation data: 9558 / 10000\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.36727724451796046\n",
      "Accuracy on training data: 48237 / 50000\n",
      "Cost on evaluation data: 0.9174788155704166\n",
      "Accuracy on evaluation data: 9559 / 10000\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.5507316475087922\n",
      "Accuracy on training data: 46374 / 50000\n",
      "Cost on evaluation data: 1.0816239485011028\n",
      "Accuracy on evaluation data: 9284 / 10000\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.3404809767604799\n",
      "Accuracy on training data: 48481 / 50000\n",
      "Cost on evaluation data: 0.9143214955871672\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.3347183945571698\n",
      "Accuracy on training data: 48512 / 50000\n",
      "Cost on evaluation data: 0.9081332484185214\n",
      "Accuracy on evaluation data: 9613 / 10000\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.32393002676469823\n",
      "Accuracy on training data: 48596 / 50000\n",
      "Cost on evaluation data: 0.918047207734018\n",
      "Accuracy on evaluation data: 9592 / 10000\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.31310163514062495\n",
      "Accuracy on training data: 48662 / 50000\n",
      "Cost on evaluation data: 0.9167082221463845\n",
      "Accuracy on evaluation data: 9613 / 10000\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.31861689640252183\n",
      "Accuracy on training data: 48633 / 50000\n",
      "Cost on evaluation data: 0.9394062152482897\n",
      "Accuracy on evaluation data: 9594 / 10000\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.29631969914664813\n",
      "Accuracy on training data: 48855 / 50000\n",
      "Cost on evaluation data: 0.9245368266140865\n",
      "Accuracy on evaluation data: 9625 / 10000\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.3005945194735425\n",
      "Accuracy on training data: 48802 / 50000\n",
      "Cost on evaluation data: 0.933868564396663\n",
      "Accuracy on evaluation data: 9615 / 10000\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.30996363531496784\n",
      "Accuracy on training data: 48737 / 50000\n",
      "Cost on evaluation data: 0.9520759833041184\n",
      "Accuracy on evaluation data: 9609 / 10000\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.29297805972339397\n",
      "Accuracy on training data: 48905 / 50000\n",
      "Cost on evaluation data: 0.9256543817147835\n",
      "Accuracy on evaluation data: 9636 / 10000\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.2893670030886165\n",
      "Accuracy on training data: 48919 / 50000\n",
      "Cost on evaluation data: 0.9318915621446743\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.28455481005619643\n",
      "Accuracy on training data: 48943 / 50000\n",
      "Cost on evaluation data: 0.9418773514956058\n",
      "Accuracy on evaluation data: 9624 / 10000\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.30656825293981493\n",
      "Accuracy on training data: 48709 / 50000\n",
      "Cost on evaluation data: 0.9592607547908456\n",
      "Accuracy on evaluation data: 9601 / 10000\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.2910494534535032\n",
      "Accuracy on training data: 48861 / 50000\n",
      "Cost on evaluation data: 0.9414737762831411\n",
      "Accuracy on evaluation data: 9632 / 10000\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.312182962101615\n",
      "Accuracy on training data: 48693 / 50000\n",
      "Cost on evaluation data: 0.9710271893172757\n",
      "Accuracy on evaluation data: 9566 / 10000\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.28840846521395924\n",
      "Accuracy on training data: 48898 / 50000\n",
      "Cost on evaluation data: 0.9443633288180344\n",
      "Accuracy on evaluation data: 9622 / 10000\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.2740551372157466\n",
      "Accuracy on training data: 49018 / 50000\n",
      "Cost on evaluation data: 0.9378602011487556\n",
      "Accuracy on evaluation data: 9641 / 10000\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.27238609088518717\n",
      "Accuracy on training data: 49061 / 50000\n",
      "Cost on evaluation data: 0.9416278199859581\n",
      "Accuracy on evaluation data: 9652 / 10000\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.26280771184024754\n",
      "Accuracy on training data: 49178 / 50000\n",
      "Cost on evaluation data: 0.9409596754967604\n",
      "Accuracy on evaluation data: 9654 / 10000\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.27997929749721695\n",
      "Accuracy on training data: 48970 / 50000\n",
      "Cost on evaluation data: 0.952601368193745\n",
      "Accuracy on evaluation data: 9626 / 10000\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.2980008197782674\n",
      "Accuracy on training data: 48837 / 50000\n",
      "Cost on evaluation data: 0.9582542208805043\n",
      "Accuracy on evaluation data: 9621 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.220550444355957,\n",
       "  2.0719999971131013,\n",
       "  1.220167426194576,\n",
       "  1.0079528829260798,\n",
       "  0.9818013019900832,\n",
       "  0.9389622529238528,\n",
       "  0.945316914386068,\n",
       "  0.905283338574934,\n",
       "  0.9174788155704166,\n",
       "  1.0816239485011028,\n",
       "  0.9143214955871672,\n",
       "  0.9081332484185214,\n",
       "  0.918047207734018,\n",
       "  0.9167082221463845,\n",
       "  0.9394062152482897,\n",
       "  0.9245368266140865,\n",
       "  0.933868564396663,\n",
       "  0.9520759833041184,\n",
       "  0.9256543817147835,\n",
       "  0.9318915621446743,\n",
       "  0.9418773514956058,\n",
       "  0.9592607547908456,\n",
       "  0.9414737762831411,\n",
       "  0.9710271893172757,\n",
       "  0.9443633288180344,\n",
       "  0.9378602011487556,\n",
       "  0.9416278199859581,\n",
       "  0.9409596754967604,\n",
       "  0.952601368193745,\n",
       "  0.9582542208805043],\n",
       " [1358,\n",
       "  5206,\n",
       "  8713,\n",
       "  9226,\n",
       "  9341,\n",
       "  9444,\n",
       "  9477,\n",
       "  9558,\n",
       "  9559,\n",
       "  9284,\n",
       "  9577,\n",
       "  9613,\n",
       "  9592,\n",
       "  9613,\n",
       "  9594,\n",
       "  9625,\n",
       "  9615,\n",
       "  9609,\n",
       "  9636,\n",
       "  9641,\n",
       "  9624,\n",
       "  9601,\n",
       "  9632,\n",
       "  9566,\n",
       "  9622,\n",
       "  9641,\n",
       "  9652,\n",
       "  9654,\n",
       "  9626,\n",
       "  9621],\n",
       " [3.1914391962703026,\n",
       "  1.9664736336015889,\n",
       "  0.9946772191561473,\n",
       "  0.6540916048660534,\n",
       "  0.5563059908524913,\n",
       "  0.4693920682452468,\n",
       "  0.4336847868181387,\n",
       "  0.3797755119085292,\n",
       "  0.36727724451796046,\n",
       "  0.5507316475087922,\n",
       "  0.3404809767604799,\n",
       "  0.3347183945571698,\n",
       "  0.32393002676469823,\n",
       "  0.31310163514062495,\n",
       "  0.31861689640252183,\n",
       "  0.29631969914664813,\n",
       "  0.3005945194735425,\n",
       "  0.30996363531496784,\n",
       "  0.29297805972339397,\n",
       "  0.2893670030886165,\n",
       "  0.28455481005619643,\n",
       "  0.30656825293981493,\n",
       "  0.2910494534535032,\n",
       "  0.312182962101615,\n",
       "  0.28840846521395924,\n",
       "  0.2740551372157466,\n",
       "  0.27238609088518717,\n",
       "  0.26280771184024754,\n",
       "  0.27997929749721695,\n",
       "  0.2980008197782674],\n",
       " [7045,\n",
       "  25739,\n",
       "  43322,\n",
       "  46082,\n",
       "  46751,\n",
       "  47482,\n",
       "  47699,\n",
       "  48127,\n",
       "  48237,\n",
       "  46374,\n",
       "  48481,\n",
       "  48512,\n",
       "  48596,\n",
       "  48662,\n",
       "  48633,\n",
       "  48855,\n",
       "  48802,\n",
       "  48737,\n",
       "  48905,\n",
       "  48919,\n",
       "  48943,\n",
       "  48709,\n",
       "  48861,\n",
       "  48693,\n",
       "  48898,\n",
       "  49018,\n",
       "  49061,\n",
       "  49178,\n",
       "  48970,\n",
       "  48837])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0,\n",
    "        evaluation_data= validation_data,\n",
    "            monitor_evaluation_cost=True,\n",
    "            monitor_evaluation_accuracy=True,\n",
    "            monitor_training_cost=True,\n",
    "            monitor_training_accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
